{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0fa2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ea9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545b47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63b36c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "VAE(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc_mu): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (fc_logvar): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (fc3): Linear(in_features=2, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Correction device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc_mu = nn.Linear(512, 2)\n",
    "        self.fc_logvar = nn.Linear(512, 2)\n",
    "        self.fc3 = nn.Linear(2, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 28*28)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        h2 = torch.relu(self.fc2(h1))\n",
    "        mu = self.fc_mu(h2)\n",
    "        logvar = self.fc_logvar(h2)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = torch.relu(self.fc3(z))\n",
    "        h4 = torch.relu(self.fc4(h3))\n",
    "        return torch.sigmoid(self.fc5(h4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "model = VAE().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76047f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x_flat, reduction='mean')\n",
    "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)) / x.size(0)\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7c4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, _) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        recon_batch, mu, logvar = model(X)\n",
    "        loss = vae_loss(recon_batch, X, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"loss: {loss.item()/len(X):>7f}  [{(batch + 1) * len(X):>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f354b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, _ in dataloader:\n",
    "            X = X.to(device)\n",
    "            recon_batch, mu, logvar = model(X)\n",
    "            test_loss += vae_loss(recon_batch, X, mu, logvar).item()\n",
    "    test_loss /= size\n",
    "    print(f\"Test set: Avg loss: {test_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af660c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.010875  [   64/60000]\n",
      "loss: 0.006595  [ 6464/60000]\n",
      "loss: 0.006493  [12864/60000]\n",
      "loss: 0.006415  [19264/60000]\n",
      "loss: 0.006221  [25664/60000]\n",
      "loss: 0.006519  [32064/60000]\n",
      "loss: 0.006179  [38464/60000]\n",
      "loss: 0.006130  [44864/60000]\n",
      "loss: 0.006336  [51264/60000]\n",
      "loss: 0.006261  [57664/60000]\n",
      "Test set: Avg loss: 0.006301\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.006153  [   64/60000]\n",
      "loss: 0.006095  [ 6464/60000]\n",
      "loss: 0.006180  [12864/60000]\n",
      "loss: 0.006309  [19264/60000]\n",
      "loss: 0.006132  [25664/60000]\n",
      "loss: 0.006388  [32064/60000]\n",
      "loss: 0.006048  [38464/60000]\n",
      "loss: 0.006033  [44864/60000]\n",
      "loss: 0.006253  [51264/60000]\n",
      "loss: 0.006166  [57664/60000]\n",
      "Test set: Avg loss: 0.006246\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.006156  [   64/60000]\n",
      "loss: 0.005981  [ 6464/60000]\n",
      "loss: 0.006206  [12864/60000]\n",
      "loss: 0.006250  [19264/60000]\n",
      "loss: 0.006087  [25664/60000]\n",
      "loss: 0.006320  [32064/60000]\n",
      "loss: 0.006062  [38464/60000]\n",
      "loss: 0.006097  [44864/60000]\n",
      "loss: 0.006337  [51264/60000]\n",
      "loss: 0.006141  [57664/60000]\n",
      "Test set: Avg loss: 0.006234\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.006157  [   64/60000]\n",
      "loss: 0.006058  [ 6464/60000]\n",
      "loss: 0.006134  [12864/60000]\n",
      "loss: 0.006198  [19264/60000]\n",
      "loss: 0.006113  [25664/60000]\n",
      "loss: 0.006352  [32064/60000]\n",
      "loss: 0.006026  [38464/60000]\n",
      "loss: 0.006053  [44864/60000]\n",
      "loss: 0.006198  [51264/60000]\n",
      "loss: 0.006219  [57664/60000]\n",
      "Test set: Avg loss: 0.006218\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.006107  [   64/60000]\n",
      "loss: 0.005991  [ 6464/60000]\n",
      "loss: 0.006110  [12864/60000]\n",
      "loss: 0.006280  [19264/60000]\n",
      "loss: 0.006046  [25664/60000]\n",
      "loss: 0.006382  [32064/60000]\n",
      "loss: 0.006060  [38464/60000]\n",
      "loss: 0.006054  [44864/60000]\n",
      "loss: 0.006205  [51264/60000]\n",
      "loss: 0.006192  [57664/60000]\n",
      "Test set: Avg loss: 0.006202\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bde58a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d284457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52cf038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]  # x is the original image, y is the label (not used for display)\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    # Add a batch dimension to the input\n",
    "    x = x.unsqueeze(0)\n",
    "    recon_x, _, _ = model(x)\n",
    "    # Reshape the output prediction back to image shape\n",
    "    reconstructed_image = recon_x.view(1, 1, 28, 28)\n",
    "\n",
    "    # Display the original and reconstructed images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    # Original Image\n",
    "    axes[0].imshow(x.squeeze().cpu().numpy(), cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Reconstructed Image\n",
    "    axes[1].imshow(reconstructed_image.squeeze().cpu().numpy(), cmap='gray')\n",
    "    axes[1].set_title('Reconstructed Image')\n",
    "    axes[1].axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
